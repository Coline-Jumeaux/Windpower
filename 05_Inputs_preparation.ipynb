{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare inputs for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import glob\n",
    "from scipy import interpolate\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Volumes/My Passport/eem20/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4004/4004 [00:21<00:00, 188.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# turbine features\n",
    "turbines = pd.read_csv('data_turbines/windturbines_fillna_shiftlon.csv')\n",
    "turbines.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1'], inplace=True)\n",
    "\n",
    "# construct weather grid\n",
    "weather = netCDF4.Dataset('data_weather/20000915T00Z.nc', 'r')\n",
    "lats = weather.variables['latitude'][:,:]\n",
    "lons = weather.variables['longitude'][:,:]\n",
    "grid = np.column_stack([lons.flatten(), lats.flatten()])\n",
    "grid_x = []\n",
    "grid_y = []\n",
    "\n",
    "# pull out latlon of turbine\n",
    "for i in tqdm.tqdm(range(len(turbines))):\n",
    "    \n",
    "    # position of turbine\n",
    "    lonlat = np.column_stack([turbines[turbines.index == i]['Longitude'].values, turbines[turbines.index == i]['Latitude'].values])\n",
    "\n",
    "    # calculate distances to weather grid positions\n",
    "    distance = cdist(grid, lonlat).reshape(169, 71, 1)\n",
    "\n",
    "    # index of closest gridpoint\n",
    "    grid_x += [np.where(distance == min(distance.flatten()))[0][0]]\n",
    "    grid_y += [np.where(distance == min(distance.flatten()))[1][0]]\n",
    "    \n",
    "# add to dataframe\n",
    "turbines.insert(len(turbines.columns), \"grid x\", grid_x, True)\n",
    "turbines.insert(len(turbines.columns), \"grid y\", grid_y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sector power\n",
    "sector_power = pd.read_csv('data_turbines/windpower_task1.csv')\n",
    "\n",
    "# cut out the missing dates: May 14 2000, September 26 2000\n",
    "drop_indices = []\n",
    "for i in range(len(sector_power)):\n",
    "    if (sector_power['Unnamed: 0'][i][3]=='0') * (sector_power['Unnamed: 0'][i][6]=='5') * (sector_power['Unnamed: 0'][i][8]=='1') * (sector_power['Unnamed: 0'][i][9]=='4'):\n",
    "        drop_indices += [i]\n",
    "        \n",
    "    if (sector_power['Unnamed: 0'][i][3]=='0') * (sector_power['Unnamed: 0'][i][6]=='9') * (sector_power['Unnamed: 0'][i][8]=='2') * (sector_power['Unnamed: 0'][i][9]=='6'):\n",
    "        drop_indices += [i]\n",
    "\n",
    "sector_power = sector_power.drop(index=drop_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split turbine data by sector\n",
    "turbines_SE1 = turbines[turbines['Price region']=='SE1']\n",
    "turbines_SE2 = turbines[turbines['Price region']=='SE2']\n",
    "turbines_SE3 = turbines[turbines['Price region']=='SE3']\n",
    "turbines_SE4 = turbines[turbines['Price region']=='SE4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort out the global time stamp list for the weather files\n",
    "\n",
    "listoffiles = (glob.glob(\"round_3/Comp_data/*.nc\"))\n",
    "time_stamps = []\n",
    "for file in listoffiles:\n",
    "    weather = netCDF4.Dataset(file, 'r')\n",
    "    units = weather.variables['time'].units\n",
    "    Timestamp = netCDF4.num2date(weather.variables['time'][:], units=units)\n",
    "    time_stamps += Timestamp.tolist()\n",
    "\n",
    "# sort into time-ordered array\n",
    "time_stamps.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [02:55<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop over weather data\n",
    "\n",
    "# weather features to process\n",
    "weather_features = ['Temperature', 'RelativeHumidity', 'WindSpeed', 'Pressure', 'CloudCover', 'WindGustSpeed']\n",
    "\n",
    "# number of time stamps\n",
    "n_times = len(time_stamps)\n",
    "\n",
    "weather_at_turbine_locations_SE1 = np.zeros(shape=(n_times, len(turbines_SE1.index), 2*len(weather_features)))\n",
    "weather_at_turbine_locations_SE2 = np.zeros(shape=(n_times, len(turbines_SE2.index), 2*len(weather_features)))\n",
    "weather_at_turbine_locations_SE3 = np.zeros(shape=(n_times, len(turbines_SE3.index), 2*len(weather_features)))\n",
    "weather_at_turbine_locations_SE4 = np.zeros(shape=(n_times, len(turbines_SE4.index), 2*len(weather_features)))\n",
    "\n",
    "# loop over netCDF weather files\n",
    "for file_index in tqdm.tqdm(range(len(listoffiles))):\n",
    "    \n",
    "    ds = netCDF4.Dataset(listoffiles[file_index], 'r')\n",
    "    units = ds.variables['time'].units\n",
    "    times = netCDF4.num2date(ds.variables['time'][:], units=units)\n",
    "    \n",
    "    # loop over hours in this day\n",
    "    for t in range(24):\n",
    "        \n",
    "        # index where this time stamp will go\n",
    "        i = time_stamps.index(times[t])\n",
    "        \n",
    "        # loop over weather features\n",
    "        for f in range(len(weather_features)):\n",
    "\n",
    "            # for wind speed, combine U and V, else just pull out the feature\n",
    "            if f == 2:\n",
    "                data = np.sqrt(ds.variables['Wind_U'][t,:,:,:]**2 + ds.variables['Wind_V'][t,:,:,:]**2)\n",
    "            else:\n",
    "                data = ds.variables[weather_features[f]][t,:,:,:]\n",
    "            \n",
    "            # mean and std-dev\n",
    "            mean = data.mean(axis=0)\n",
    "            sd = data.std(axis=0)\n",
    "            \n",
    "            weather_at_turbine_locations_SE1[i,:,2*f] = mean[turbines_SE1['grid x'].values,turbines_SE1['grid y'].values]\n",
    "            weather_at_turbine_locations_SE1[i,:,2*f+1] = sd[turbines_SE1['grid x'].values,turbines_SE1['grid y'].values]\n",
    "    \n",
    "            weather_at_turbine_locations_SE2[i,:,2*f] = mean[turbines_SE2['grid x'].values,turbines_SE2['grid y'].values]\n",
    "            weather_at_turbine_locations_SE2[i,:,2*f+1] = sd[turbines_SE2['grid x'].values,turbines_SE2['grid y'].values]\n",
    "\n",
    "            weather_at_turbine_locations_SE3[i,:,2*f] = mean[turbines_SE3['grid x'].values,turbines_SE3['grid y'].values]\n",
    "            weather_at_turbine_locations_SE3[i,:,2*f+1] = sd[turbines_SE3['grid x'].values,turbines_SE3['grid y'].values]\n",
    "\n",
    "            weather_at_turbine_locations_SE4[i,:,2*f] = mean[turbines_SE4['grid x'].values,turbines_SE4['grid y'].values]\n",
    "            weather_at_turbine_locations_SE4[i,:,2*f+1] = sd[turbines_SE4['grid x'].values,turbines_SE4['grid y'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the turbine feature data to only contain the four relevant things\n",
    "turbine_features = ['Terrain height [m]', 'Nacelle height [m]', 'Rotor diameter [m]', 'Max power [MW]']\n",
    "\n",
    "turbines_SE1 = np.column_stack([turbines[turbines['Price region']=='SE1'][turbine_features[i]].values for i in range(len(turbine_features))])\n",
    "turbines_SE2 = np.column_stack([turbines[turbines['Price region']=='SE2'][turbine_features[i]].values for i in range(len(turbine_features))])\n",
    "turbines_SE3 = np.column_stack([turbines[turbines['Price region']=='SE3'][turbine_features[i]].values for i in range(len(turbine_features))])\n",
    "turbines_SE4 = np.column_stack([turbines[turbines['Price region']=='SE4'][turbine_features[i]].values for i in range(len(turbine_features))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation dates\n",
    "installation_dates = []\n",
    "for sector in ['SE1', 'SE2', 'SE3', 'SE4']:\n",
    "    \n",
    "    turbines_sector = turbines[turbines['Price region']==sector].reset_index()\n",
    "    \n",
    "    installation_date = []\n",
    "    for i in range(len(turbines_sector)):\n",
    "        if turbines_sector['Installation date'][i] == '1881-12-31':\n",
    "            installation_date += [datetime.datetime.strptime(turbines_sector['Installation date'][i], '%Y-%m-%d')]\n",
    "        else:\n",
    "            installation_date += [datetime.datetime.strptime(turbines_sector['Installation date'][i], '%d/%m/%y')]\n",
    "    \n",
    "    # re-base dates (eg., `64 should be 1964, not 2064 as come out from the above)\n",
    "    for i in range(len(installation_date)):\n",
    "        if installation_date[i].year > 2020:\n",
    "            installation_date[i] = installation_date[i].replace(year = installation_date[i].year - 100)\n",
    "        \n",
    "    installation_dates.append(installation_date)\n",
    "    \n",
    "installed = []\n",
    "for s in range(4):\n",
    "    \n",
    "    install = np.zeros((len(time_stamps), len(installation_dates[s]), 1))\n",
    "    \n",
    "    # compare install dates to the weather time stamps\n",
    "    for i in range(len(time_stamps)):\n",
    "        for j in range(len(installation_dates[s])):\n",
    "            install[i,j,0] = int(installation_dates[s][j] < time_stamps[i])\n",
    "    \n",
    "    installed.append(install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save everything to file\n",
    "\n",
    "np.save('round_3/data_prepared/weather_at_turbine_locations_SE1.npy', weather_at_turbine_locations_SE1)\n",
    "np.save('round_3/data_prepared/weather_at_turbine_locations_SE2.npy', weather_at_turbine_locations_SE2)\n",
    "np.save('round_3/data_prepared/weather_at_turbine_locations_SE3.npy', weather_at_turbine_locations_SE3)\n",
    "np.save('round_3/data_prepared/weather_at_turbine_locations_SE4.npy', weather_at_turbine_locations_SE4)\n",
    "\n",
    "np.save('round_3/data_prepared/turbines_SE1.npy', turbines_SE1)\n",
    "np.save('round_3/data_prepared/turbines_SE2.npy', turbines_SE2)\n",
    "np.save('round_3/data_prepared/turbines_SE3.npy', turbines_SE3)\n",
    "np.save('round_3/data_prepared/turbines_SE4.npy', turbines_SE4)\n",
    "\n",
    "np.save('round_3/data_prepared/sector_power_SE1.npy', np.atleast_2d(sector_power['SE1'].values).T)\n",
    "np.save('round_3/data_prepared/sector_power_SE2.npy', np.atleast_2d(sector_power['SE2'].values).T)\n",
    "np.save('round_3/data_prepared/sector_power_SE3.npy', np.atleast_2d(sector_power['SE3'].values).T)\n",
    "np.save('round_3/data_prepared/sector_power_SE4.npy', np.atleast_2d(sector_power['SE4'].values).T)\n",
    "\n",
    "np.save('round_3/data_prepared/installed_SE1.npy', installed[0])\n",
    "np.save('round_3/data_prepared/installed_SE2.npy', installed[1])\n",
    "np.save('round_3/data_prepared/installed_SE3.npy', installed[2])\n",
    "np.save('round_3/data_prepared/installed_SE4.npy', installed[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate shifts and scales for the turbine feature and weather inputs\n",
    "\n",
    "turbine_features_shift = np.median(np.row_stack([turbines_SE1, turbines_SE2, turbines_SE3, turbines_SE4]), axis=0)\n",
    "turbine_features_scale = np.max(np.row_stack([turbines_SE1, turbines_SE2, turbines_SE3, turbines_SE4]), axis=0) - np.min(np.row_stack([turbines_SE1, turbines_SE2, turbines_SE3, turbines_SE4]), axis=0)\n",
    "\n",
    "weather_features_shift = np.median(np.concatenate([weather_at_turbine_locations_SE1,\n",
    "                                        weather_at_turbine_locations_SE2,\n",
    "                                        weather_at_turbine_locations_SE3,\n",
    "                                        weather_at_turbine_locations_SE4], axis=1), axis=(0,1))\n",
    "\n",
    "weather_features_scale = np.max(np.concatenate([weather_at_turbine_locations_SE1,\n",
    "                                        weather_at_turbine_locations_SE2,\n",
    "                                        weather_at_turbine_locations_SE3,\n",
    "                                        weather_at_turbine_locations_SE4], axis=1), axis=(0,1)) - \\\n",
    "                         np.min(np.concatenate([weather_at_turbine_locations_SE1,\n",
    "                                        weather_at_turbine_locations_SE2,\n",
    "                                        weather_at_turbine_locations_SE3,\n",
    "                                        weather_at_turbine_locations_SE4], axis=1), axis=(0,1))\n",
    "\n",
    "np.save('data_prepared/turbine_features_shift.npy', turbine_features_shift)\n",
    "np.save('data_prepared/turbine_features_scale.npy', turbine_features_scale)\n",
    "np.save('data_prepared/weather_features_shift.npy', weather_features_shift)\n",
    "np.save('data_prepared/weather_features_scale.npy', weather_features_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
