{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch import matmul\n",
    "from torch import tanh\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn.functional import leaky_relu\n",
    "from torch import sigmoid\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Volumes/My Passport/eem20/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Neural Density Estimator (2-layer version)\n",
    "# takes some inputs (turbine properties and weather forecasts) and outputs a mean and (log) variance describing a Gaussian distribution for the predicted power output\n",
    "class GaussianNDE(nn.Module):\n",
    "    \n",
    "    # init\n",
    "    def __init__(self, n_turbine_features, n_weather_features, n_units=[64,64], activation=leaky_relu, mean_init=0, logvar_init=1.):\n",
    "        \n",
    "        super(GaussianNDE, self).__init__()\n",
    "        \n",
    "        # architecture: (n_turbines, n_weather) -> hidden layers (n_units) -> 2 outputs (mean and log variance)\n",
    "        self.n_turbine_features = n_turbine_features\n",
    "        self.n_weather_features = n_weather_features\n",
    "        self.n_units = n_units\n",
    "        \n",
    "        # network weights\n",
    "        self.W1t = nn.Parameter(torch.Tensor(self.n_turbine_features, self.n_units[0]).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        self.W1w = nn.Parameter(torch.Tensor(self.n_weather_features, self.n_units[0]).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        self.W2 = nn.Parameter(torch.Tensor(self.n_units[0], self.n_units[1]).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        self.W3 = nn.Parameter(torch.Tensor(self.n_units[1], 2).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        \n",
    "        # network biases\n",
    "        self.b1 = nn.Parameter(torch.Tensor(self.n_units[0]).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        self.b2 = nn.Parameter(torch.Tensor(self.n_units[1]).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        self.b3 = nn.Parameter(torch.Tensor(2).normal_(mean=0, std=1e-5), requires_grad=True)\n",
    "        \n",
    "        # initialize the bias of the output layer\n",
    "        self.b3[0].data.fill_(mean_init)\n",
    "        self.b3[1].data.fill_(logvar_init)\n",
    "\n",
    "        # activation\n",
    "        self.activation = activation\n",
    "    \n",
    "    # forward pass through the network\n",
    "    def forward(self, turbine_features, weather_features):\n",
    "        \n",
    "        # forward pass through two hidden layers (including split input layer)\n",
    "        output = torch.matmul(self.activation(torch.matmul(self.activation(torch.matmul(turbine_features, self.W1t) + torch.matmul(weather_features, self.W1w) + self.b1), self.W2) + self.b2), self.W3) + self.b3\n",
    "        \n",
    "        # split the output layer into two outputs: mean nd log variance (log_variance)\n",
    "        mean, log_variance = torch.split(output, 1, dim=-1)\n",
    "               \n",
    "        return mean, log_variance\n",
    "    \n",
    "    # batched forward pass\n",
    "    def batched_forward(self, turbine_features, weather_features):\n",
    "        \n",
    "        # forward pass through two hidden layers (including split input layer)\n",
    "        output = torch.einsum(\"ijk,kl->ijl\", self.activation(torch.einsum(\"ijk,kl->ijl\", self.activation(torch.einsum(\"ijk,kl->ijl\", turbine_features, self.W1t) + torch.einsum(\"ijk,kl->ijl\", weather_features, self.W1w) + self.b1), self.W2) + self.b2), self.W3) + self.b3\n",
    "        \n",
    "        # split the output layer into two outputs: mean nd log variance (log_variance)\n",
    "        mean, log_variance = torch.split(output, 1, dim=-1)\n",
    "               \n",
    "        return mean, log_variance\n",
    "\n",
    "# same as above but with generic network depth\n",
    "class GaussianNDE_Deep(nn.Module):\n",
    "    \n",
    "    # init\n",
    "    def __init__(self, n_inputs, n_units=[64,64], activation=leaky_relu):\n",
    "        \n",
    "        super(GaussianNDE, self).__init__()\n",
    "        \n",
    "        # architecture: n_inputs -> hidden layers (n_units) -> 2 outputs (mean and variance)\n",
    "        self.n_inputs = n_inputs # n_inputs = number of turbine features + number of weather features (ie., total length of input feature vector)\n",
    "        self.architecture = [self.n_inputs] + n_units + [2]\n",
    "        self.n_layers = len(self.architecture) - 1\n",
    "        \n",
    "        # network weights and biases\n",
    "        self.W = nn.ParameterList([nn.Parameter(torch.Tensor(self.architecture[i], self.architecture[i+1]), requires_grad=True) for i in range(self.n_layers)])\n",
    "        self.b = nn.ParameterList([nn.Parameter(torch.Tensor(self.architecture[i+1]), requires_grad=True) for i in range(self.n_layers)])\n",
    "        \n",
    "        # activation\n",
    "        self.activation = activation\n",
    "    \n",
    "    # forward pass through the network\n",
    "    def forward(self, turbine_features, weather_features):\n",
    "        \n",
    "        # initialize input layer: concatenate the turbine features and weather features together into a single input vector\n",
    "        layers = [torch.cat((turbine_features, weather_features), -1)]\n",
    "        \n",
    "        # implement network\n",
    "        for i in range(self.n_layers):\n",
    "            layers.append(self.activation(matmul(layers[-1], self.W[i]) + self.b[i]))\n",
    "        \n",
    "        # split the output layer into two outputs: mean nd log variance (log_variance)\n",
    "        mean, log_variance = torch.split(layers[-1], 1, dim=-1)\n",
    "               \n",
    "        return mean, log_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your data here\n",
    "\n",
    "# turbine features\n",
    "turbines_SE1 = torch.tensor(np.load('data_prepared/turbines_SE1.npy'))\n",
    "turbines_SE2 = torch.tensor(np.load('data_prepared/turbines_SE2.npy'))\n",
    "turbines_SE3 = torch.tensor(np.load('data_prepared/turbines_SE3.npy'))\n",
    "turbines_SE4 = torch.tensor(np.load('data_prepared/turbines_SE4.npy'))\n",
    "turbine_features_shift = torch.tensor(np.load('data_prepared/turbine_features_shift.npy'))\n",
    "turbine_features_scale = torch.tensor(np.load('data_prepared/turbine_features_scale.npy'))\n",
    "turbine_features = [(turbines_SE1 - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE2 - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE3 - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE4 - turbine_features_shift)/turbine_features_scale]\n",
    "\n",
    "# weather\n",
    "weather_SE1 = torch.tensor(np.load('data_prepared/weather_at_turbine_locations_SE1.npy'))\n",
    "weather_SE2 = torch.tensor(np.load('data_prepared/weather_at_turbine_locations_SE2.npy'))\n",
    "weather_SE3 = torch.tensor(np.load('data_prepared/weather_at_turbine_locations_SE3.npy'))\n",
    "weather_SE4 = torch.tensor(np.load('data_prepared/weather_at_turbine_locations_SE4.npy'))\n",
    "weather_features_shift = torch.tensor(np.load('data_prepared/weather_features_shift.npy'))\n",
    "weather_features_scale = torch.tensor(np.load('data_prepared/weather_features_scale.npy'))\n",
    "weather = [(weather_SE1 - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE2 - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE3 - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE4 - weather_features_shift)/weather_features_scale]\n",
    "\n",
    "# installed or not?\n",
    "installed_SE1 = torch.tensor(np.load('data_prepared/installed_SE1.npy'))\n",
    "installed_SE2 = torch.tensor(np.load('data_prepared/installed_SE2.npy'))\n",
    "installed_SE3 = torch.tensor(np.load('data_prepared/installed_SE3.npy'))\n",
    "installed_SE4 = torch.tensor(np.load('data_prepared/installed_SE4.npy'))\n",
    "installed = [installed_SE1, installed_SE2, installed_SE3, installed_SE4]\n",
    "\n",
    "# sector energy\n",
    "sector_power_SE1 = torch.tensor(np.load('data_prepared/sector_power_SE1.npy'))\n",
    "sector_power_SE2 = torch.tensor(np.load('data_prepared/sector_power_SE2.npy'))\n",
    "sector_power_SE3 = torch.tensor(np.load('data_prepared/sector_power_SE3.npy'))\n",
    "sector_power_SE4 = torch.tensor(np.load('data_prepared/sector_power_SE4.npy'))\n",
    "sector_power = [sector_power_SE1, sector_power_SE2, sector_power_SE3, sector_power_SE4]\n",
    "\n",
    "# number of time-steps, sectors, turbine features and weather features\n",
    "n_times = weather_SE1.shape[0]\n",
    "n_turbine_features = turbine_features[0].shape[-1]\n",
    "n_weather_features = weather[0].shape[-1]\n",
    "n_sectors = 4\n",
    "\n",
    "# mean and std of power for init\n",
    "mean_init = torch.mean(sector_power[0])/len(turbines_SE1)\n",
    "logvar_init = torch.log( torch.var(sector_power[0])/len(turbines_SE1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10152, 472, 12])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a neural network model for the turbine power outputs\n",
    "Model = GaussianNDE(n_turbine_features=n_turbine_features, \n",
    "                    n_weather_features=n_weather_features, \n",
    "                    n_units=[64, 64], \n",
    "                    activation=leaky_relu,\n",
    "                    mean_init=mean_init,\n",
    "                    logvar_init=logvar_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 1e-2\n",
    "epochs = 20\n",
    "adam_regularisation = 0.0\n",
    "\n",
    "# optimizer\n",
    "optimiser = torch.optim.Adam(Model.parameters(), lr=learning_rate, weight_decay=adam_regularisation)\n",
    "\n",
    "# sector\n",
    "sector = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076949b43f574a95a7a79495a2d959d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=20.0, style=ProgressStyle(description_widtâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e48cd12c3991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# calculate the predicted means and variances for those turbines in that sector, at that time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# note: turbine features is n_turbines x n_features, and weather is n_times x n_turbines x n_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_variances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturbine_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# calculate the predicted mean and variance for the whole sector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-39147ae3aa2f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, turbine_features, weather_features)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# forward pass through two hidden layers (including split input layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturbine_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# split the output layer into two outputs: mean nd log variance (log_variance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MSE training loop\n",
    "\n",
    "# progress bar\n",
    "pbar = tqdm.tqdm_notebook(total=epochs, desc = \"Training\")\n",
    "pbar.set_postfix(ordered_dict={\"loss\":0}, refresh=True)\n",
    "\n",
    "# holder for training loss\n",
    "training_loss = []\n",
    "\n",
    "# loop over epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # construct batches\n",
    "    batches = np.random.permutation(np.arange(10000)).reshape(10, 1000)\n",
    "    \n",
    "    # loop over time batches\n",
    "    for t in range(len(batches)):\n",
    "        \n",
    "        batch = batches[t]\n",
    "        \n",
    "        # initialize the loss\n",
    "        #loss = torch.tensor(0.0, requires_grad=True)\n",
    "        \n",
    "        # loop over sectors\n",
    "        for s in [sector]:\n",
    "\n",
    "                # calculate the predicted means and variances for those turbines in that sector, at that time\n",
    "                # note: turbine features is n_turbines x n_features, and weather is n_times x n_turbines x n_features\n",
    "                means, log_variances = Model(turbine_features[s], weather[s][batch,:,:])\n",
    "\n",
    "                # calculate the predicted mean and variance for the whole sector\n",
    "                # note that we multiply by \"installed\", which will kill any terms coming from turbines that were not installed at this time\n",
    "                # installed is n_times x n_turbines\n",
    "                sector_mean = torch.sum(means * installed[s][batch,:,:], axis=1)\n",
    "                sector_variance = torch.sum(torch.exp(log_variances) * installed[s][batch,:,:], axis=1)\n",
    "\n",
    "                # calculate log_likelihoods\n",
    "                #neg_log_likelihood = 0.5*(sector_power[s][batch,:] - sector_mean).pow(2)/sector_variance + 0.5*torch.log(sector_variance)\n",
    "                neg_log_likelihood = torch.sqrt(torch.mean((sector_power[s][batch,:] - sector_mean).pow(2)))\n",
    "                \n",
    "                # add to the loss: this is the negative log-likelihood of a gaussian with the predicted sector mean and variance from above\n",
    "                #loss = loss + torch.sum(neg_log_likelihood)\n",
    "                loss = neg_log_likelihood\n",
    "\n",
    "        # backpropagation step (ie., gradient descent step)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        pbar.set_postfix(ordered_dict={\"loss\":loss.data.clone().numpy().flatten()[0]}, refresh=True)\n",
    "        \n",
    "    # save training loss\n",
    "    training_loss.append(loss.data.clone().numpy().flatten()[0])\n",
    "\n",
    "    # update progress bar\n",
    "    pbar.update(1)\n",
    "    pbar.set_postfix(ordered_dict={\"loss\":training_loss[-1]}, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for SE1\n",
    "\n",
    "t0 = 0\n",
    "t1 = 1024\n",
    "mean, logvar = Model(turbine_features[sector], weather[sector][t0:t1,:,:])\n",
    "sector_mean = torch.sum(mean * installed[sector][t0:t1,:,:], axis=1).detach().numpy()[:,0]\n",
    "sector_std = torch.sqrt(torch.sum(torch.exp(logvar) * installed[sector][t0:t1,:,:], axis=1)).detach().numpy()[:,0]\n",
    "\n",
    "plt.fill_between(np.arange(t0, t1), sector_mean - sector_std, sector_mean + sector_std, alpha=0.1)\n",
    "plt.plot(np.arange(t0, t1), sector_mean, color = 'red', label='model')\n",
    "plt.plot(np.arange(t0, t1), sector_power[sector][t0:t1], color = 'blue', label='data')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(t0, t1), sector_mean-sector_power[sector][t0:t1].detach().numpy()[:,0], label='residuals')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std deviation on predictions\n",
    "mean, logvar = Model(turbine_features[sector], weather[sector])\n",
    "p = sector_power[sector].detach().numpy()[:,0]\n",
    "sector_mean = torch.clamp(torch.sum(mean * installed[sector], axis=1), min(p), max(p)).detach().numpy()[:,0]\n",
    "error_std = np.std(sector_mean - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_std)\n",
    "print(np.std(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "# load in data\n",
    "# turbine features\n",
    "turbines_SE1_v = torch.tensor(np.load('round2_data_prepared/turbines_SE1.npy'))\n",
    "turbines_SE2_v = torch.tensor(np.load('round2_data_prepared/turbines_SE2.npy'))\n",
    "turbines_SE3_v = torch.tensor(np.load('round2_data_prepared/turbines_SE3.npy'))\n",
    "turbines_SE4_v = torch.tensor(np.load('round2_data_prepared/turbines_SE4.npy'))\n",
    "turbine_features_shift = torch.tensor(np.load('data_prepared/turbine_features_shift.npy'))\n",
    "turbine_features_scale = torch.tensor(np.load('data_prepared/turbine_features_scale.npy'))\n",
    "turbine_features_v = [(turbines_SE1_v - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE2_v - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE3_v - turbine_features_shift)/turbine_features_scale, \n",
    "                    (turbines_SE4_v - turbine_features_shift)/turbine_features_scale]\n",
    "\n",
    "# weather\n",
    "weather_SE1_v = torch.tensor(np.load('round2_data_prepared/weather_at_turbine_locations_SE1.npy'))\n",
    "weather_SE2_v = torch.tensor(np.load('round2_data_prepared/weather_at_turbine_locations_SE2.npy'))\n",
    "weather_SE3_v = torch.tensor(np.load('round2_data_prepared/weather_at_turbine_locations_SE3.npy'))\n",
    "weather_SE4_v = torch.tensor(np.load('round2_data_prepared/weather_at_turbine_locations_SE4.npy'))\n",
    "weather_features_shift = torch.tensor(np.load('data_prepared/weather_features_shift.npy'))\n",
    "weather_features_scale = torch.tensor(np.load('data_prepared/weather_features_scale.npy'))\n",
    "weather_v = [(weather_SE1_v - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE2_v - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE3_v - weather_features_shift)/weather_features_scale, \n",
    "           (weather_SE4_v - weather_features_shift)/weather_features_scale]\n",
    "\n",
    "# installed or not?\n",
    "installed_SE1_v = torch.tensor(np.load('round2_data_prepared/installed_SE1.npy'))\n",
    "installed_SE2_v = torch.tensor(np.load('round2_data_prepared/installed_SE2.npy'))\n",
    "installed_SE3_v = torch.tensor(np.load('round2_data_prepared/installed_SE3.npy'))\n",
    "installed_SE4_v = torch.tensor(np.load('round2_data_prepared/installed_SE4.npy'))\n",
    "installed_v = [installed_SE1_v, installed_SE2_v, installed_SE3_v, installed_SE4_v]\n",
    "\n",
    "# sector energy\n",
    "sector_power_SE1_v = torch.tensor(np.load('round2_data_prepared/sector_power_SE1.npy'))\n",
    "sector_power_SE2_v = torch.tensor(np.load('round2_data_prepared/sector_power_SE2.npy'))\n",
    "sector_power_SE3_v = torch.tensor(np.load('round2_data_prepared/sector_power_SE3.npy'))\n",
    "sector_power_SE4_v = torch.tensor(np.load('round2_data_prepared/sector_power_SE4.npy'))\n",
    "sector_power_v = [sector_power_SE1_v, sector_power_SE2_v, sector_power_SE3_v, sector_power_SE4_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct percentiles\n",
    "means, _ = Model(turbine_features_v[sector], weather_v[sector])\n",
    "sector_mean = torch.sum(means * installed_v[sector], axis=1).detach().numpy()[:,0]\n",
    "maximum = np.max(sector_power[sector].detach().numpy())\n",
    "\n",
    "percentiles = np.zeros((len(weather_v[sector]), 9))\n",
    "\n",
    "for i in range(len(weather_v[sector])):\n",
    "    \n",
    "    samples = np.random.normal(sector_mean[i], error_std, 10000)\n",
    "    samples[(samples > 0) * (samples < maximum)]\n",
    "    percentiles[i,:] = np.percentile(samples, [10, 20, 30, 40, 50, 60, 70, 80, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('round2_percentiles/percentiles_SE{}.npy'.format(sector+1), percentiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
